# エンゲージメントを考えてみよう
## はじめに
”あんなスキルがあったらうれしい”、”こんなスキルが作れたら楽しそう” Voiceflowでは、思いついたらすぐにスキル開発を始めることができます。  
せっかく作るのであれば、使う人が喜んでくれたり使いやすいスキルを作りたいですよね。@<br>{}

本章では、はやる気持ちを少し抑えて、愛着を持ってもらえるスキルを作るにはどうしたらよいか？を考えてみたいと思います。

### 対象読者
本章が対象とするのは下記の方です。

- ちょっとだけVoiceflowをさわったことがある方
- VUIアシスタントとの会話が素っ気なく感じる方

## 意識しよう
### エンゲージメントとは
エンゲージメントとは、ざっくり言うと親近感・愛着・思い入れといった「繋がり」のことです。@<br>{}

エンゲージメントを高めるには、”スキルを使う人はどんな人か”、”スキルを使ったら何が嬉しいのか”を考えてたうえでスキルを作る必要があります。
ユーザーを深く知る（具体的に定義する）ために、「ペルソナ」というツールを使います。

### ペルソナとは
ペルソナとは、サービスにとって最も典型的なユーザー像のことです。  
ユーザー像を具体的にして、ユーザーにフィットさせることで、より満足度の高いサービスを提供できるようになります。  

//embed[latex]{
\clearpage
//}

あまり深く考える必要はありません。  
専門的なことを知らずにスキル開発できるのがVoiceflowの強みですので、「ある人専用のスキルを作るために、ある人がどんな人かイメージを固める」という捉え方で良いです。@<br>{}

ペルソナを設定しておくメリットとして、次の３つがあります。
> - 担当者間で、共通した人物像を形成できる
> - ユーザー視点の精度を高めることができる
> - 時間、コストの削減ができる

ferretより。URL: https://ferret-plus.com/8116

## サンプルスキルの開発
それでは、エンゲージメントを考えながらスキル開発をしていきましょう。@<br>{}

例えば「小学校の子どもが時間割を確認するスキル」を思いついたとします。  
”小学生”では抽象的なので、もっとユーザーに寄せていきます。

### ペルソナの設定
ペルソナの設定をしてみましょう。  
具体的なユーザーが決まっていれば、そのユーザーをイメージして整理をします。  
整理する内容については様々な考え方がありますが、最初は分かっていることを並べるだけでもよいと思います。  
大事なのは、この時点で「情報の取捨選択をしない」ことです。どこでどう役立つか分かりませんので、選択肢は残しておきましょう。@<br>{}

ここでは、同じテーマであっても求められるものに違いが出ることが分かるように、二人の小学生のペルソナを書いてみます。

![長女と次女のペルソナ](images/chapxx-magistralla/persona1.png)

あっさりめですが、それぞれのペルソナに沿った時間割のスキルを考えていくと

- 長女は、もうすぐ小学四年生であることから、自分で翌日の準備ができることが想像できるので「準備ができた後に、確認をしてあげるスキル」
- 次女は、まだ入学前であることから、一人で翌日の準備をすることに不慣れなので「一緒に準備を進めてあげるスキル」

が喜ばれそうです。@<br>{}

このように、ユーザーについて整理をすると、同じテーマのスキルであっても求められるものに違い出ることがわかります。

### UIの検討
次にそのスキルのUIについて検討をします。  
VoiceUIありきで考え始めましたが、このタイミングで本当にその必要があるかを考えて下さい。  
その際に入力も出力も音声で検討する必要はありません。既存のUIと組み合わせることも可能なので、ユーザーの体験向上に一番効果の高いものを考えましょう。@<br>{}

![UIの組み合わせ](images/chapxx-magistralla/type1.png)

例題では、スキルを使う子供たちの利用シーンを下記とイメージしました。

- 学校から配布された時間割を見ているため視線が奪われている
- ランドセルの中の教科書を出し入れするため両手が使えない

したがって、入出力ともに音声のタイプAが適していると考えました。

//embed[latex]{
\clearpage
//}

### 会話フローと内容
ペルソナを設定したことで、それぞれの状況や課題が明確になり、長女と次女で会話や内容を変える必要があることが分かりました。  
それぞれのペルソナに沿って、会話フローと内容を考えます。

#### 長女の場合
自分で翌日の準備ができるので、準備したものを長女に発話させ、アシスタントがOK/NGを判定するようにしました。  
アシスタントとクイズ形式で会話し、正解をすることが楽しくなることを狙います。

![長女用の会話フロー](images/chapxx-magistralla/alice01.png)

#### 次女の場合
自分で準備ができるようになってほしいので、アシスタントが準備する物を発話し、できた/できないを答えさせるようにしました。  
こちらも、自分で準備することが楽しくなっていくことを狙います。

![次女用の会話フロー](images/chapxx-magistralla/suzu01.png)

//embed[latex]{
\clearpage
//}

### Voiceflowでスキル作成
テーマも会話フローも同じですが、会話内容はそれぞれに特化した内容になっており、エンゲージメントが高くなっていると言えます。  
この設計書に沿ってVoiceflowでスキルを作ってみましょう。@<br>{}

例題では、次女の会話フローからスキルを作ります。

![発話とブロック](images/chapxx-magistralla/suzu02.png)

![会話フローをVoiceflowで実装](images/chapxx-magistralla/base.png)

これで次女専用のスキルが出来上がりました。

//embed[latex]{
\clearpage
//}

## エンゲージメントを高めるために
### シノニム
人間同士の会話では、無意識に「はい」と「YES」を同義語として認識しますが、アシスタントは、同義語かどうかを判別してくれません。
そこで、ユーザーが言いそうな同義語（言い間違えも含めて）を登録し、スムーズな会話となるようにします。@<br>{}

例題では、「できました」に同義語を登録していきます。

![発話とブロック](images/chapxx-magistralla/suzu03.png)

![シノニム](images/chapxx-magistralla/synonym.png)

これで「準備はできましたか？」の問いに対して、「できました」「できた」「はい」「うん」と答えることができるようになりました。

//embed[latex]{
\clearpage
//}

### 日時の情報
スキルが使われた日付情報を使い、曜日や時間帯に合わせてメッセージを変えたり、ユーザーのカレンダー等に合わせた会話が可能になります。@<br>{}

例題では、習いごとの前日は、ピアノを応援するメッセージを追加で言うようにします。  

「code」ブロックの使い方は、Voiceflowのフォーラムにありますので参考にしてください。  
https://forum.voiceflow.com/t/getting-the-users-time-zone-in-your-skill/314

![発話とブロック](images/chapxx-magistralla/suzu04.png)

![曜日](images/chapxx-magistralla/weekday.png)

これで、ピアノの前日に「明日はピアノですね」と伝えることができるようになりました。

//embed[latex]{
\clearpage
//}

### SSML
SSMLとは、Speech Synthesis Markup Language（合成音声マークアップ言語）と呼ばれ、会話の言葉を含めた様々な音声情報をXMLベースで表現したものです。  
発話のスピードを「早くする」「大きくする」「イントネーションをかえる」など、ユーザーに効果的に訴えかけやすくなります。  
ベンダー毎にサポートされているタグが異なったり、独自のタグがありますので、使う場合はどのタグが使えるのか確認をしてから使いましょう。

- alexa
  - https://developer.amazon.com/ja-JP/docs/alexa/custom-skills/speech-synthesis-markup-language-ssml-reference.html
- google
  - https://cloud.google.com/text-to-speech/docs/ssml?hl=ja


#### サウンドライブラリ
アシスタントで、効果音を鳴らしたい時は、サウンドライブラリを使ってみましょう。  
サウンドライブラリとは、それぞれのベンダーがスキル用の効果音として公開しているもので自由に使うことができます。

- Alexa Skills Kitサウンドライブラリ
  - https://developer.amazon.com/ja-JP/docs/alexa/custom-skills/ask-soundlibrary.html
- Google Assistant Sound Library
  - https://developers.google.com/assistant/tools/sound-library

例題では、「準備はできましたか？」の問いに対して「できました」と回答した場合、ベンダーが用意している音声ファイルを使って効果音を鳴らします。  
「speak」ブロックに`audio`タグを入力します。Alexaスキルの場合、サウンドライブラリでタグのコピーが可能ですので、コピペします。

```
<audio src="soundbank://soundlibrary/ui/gameshow/amzn_ui_sfx_gameshow_positive_response_01"/>
```

![発話とブロック](images/chapxx-magistralla/suzu05.png)

![サウンドライブラリ](images/chapxx-magistralla/soundlib.png)

これで、正解をサウンドで伝えることができるようになりました。

//embed[latex]{
\clearpage
//}

#### Speechcons
アシスタントとの会話で、淡々と聞こえてしまう時は、Speechconを使ってみましょう。@<br>{}
Speechconとは、アシスタントが表情豊かに発話してくれる特別な言葉で、専用のタグで囲むことで使うことができます。

- Alexa
  - https://developer.amazon.com/ja-JP/docs/alexa/custom-skills/speechcon-reference-interjections-japanese.html

//@<br>{}
例題では、最初のあいさつ「こんにちは」をSpeechconを使って発話させます。  
「speak」ブロックに`say-as`タグ、属性`interpret-as="interjection"`を入力します。

```
<say-as interpret-as="interjection">こんにちは</say-as>
```

![発話とブロック](images/chapxx-magistralla/suzu06.png)

![Speechcon](images/chapxx-magistralla/speechcon.png)

これで、「こんにちは」が表情豊かになりました。

## おわりに
他にも

- BlocksメニューのUserカテゴリ「user info」にてユーザー固有の情報を使う
- BlocksメニューのAdvancedカテゴリ「Integrations」にて外部と連携する

など、エンゲージメントを高めるための機能がVoiceflowにはありますので、愛着を持って使ってもらえるスキル開発を楽しみましょう。
